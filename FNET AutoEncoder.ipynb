{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep CNN-LSTM with Word Embeddings for News Headline Sarcasm Detection\n",
    "Created by Paul K. Mandal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is based off of a paper that I submitted in ITNG 2019 titled \"Deep CNN-LSTM with Word Embeddings for News Headline Sarcasm Detection.\" Unfortunately, the code was wiped off of my computer before I pushed it to github. Thus, there might be some slight variations in hyperparameters than what was outlined in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "for line in open('Sarcasm_Headlines_Dataset.json', 'r'):\n",
    "    data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "y_vals = []\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    titles.append(data[i]['headline'])\n",
    "    y_vals.append(data[i]['is_sarcastic'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_titles = []\n",
    "fake_titles = []\n",
    "\n",
    "for i in range(0,len(titles)):\n",
    "    if y_vals[i] == 0:\n",
    "        real_titles.append(titles[i])\n",
    "    else:\n",
    "        fake_titles.append(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the 'roseanne' revival catches up to our thorny political mood, for better and worse\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_titles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = real_titles[:1500]\n",
    "x_train = real_titles[1500:]\n",
    "x_val = x_train[:1500]\n",
    "x_partial_train = x_train[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_partial_train, x_partial_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val,x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def preprocess_text(sentence):\n",
    "    sentence = tf.strings.lower(sentence)\n",
    "    # Adding a space between the punctuation and the last word to allow better tokenization\n",
    "    sentence = tf.strings.regex_replace(sentence, r\"([?.!,])\", r\" \\1 \")\n",
    "    # Replacing multiple continuous spaces with a single space\n",
    "    sentence = tf.strings.regex_replace(sentence, r\"\\s\\s+\", \" \")\n",
    "    # Replacing non english words with spaces\n",
    "    sentence = tf.strings.regex_replace(sentence, r\"[^a-z?.!,]+\", \" \")\n",
    "    sentence = tf.strings.strip(sentence)\n",
    "    sentence = tf.strings.join([\"[start]\", sentence, \"[end]\"], separator=\" \")\n",
    "    return sentence\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_LENGTH = 20\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "#VOCAB_SIZE = max_words\n",
    "MAX_SAMPLES = 50000\n",
    "BUFFER_SIZE = 20000\n",
    "#MAX_LENGTH = maxlen\n",
    "EMBED_DIM = 256\n",
    "LATENT_DIM = 512\n",
    "NUM_HEADS = 8\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    VOCAB_SIZE,\n",
    "    standardize=preprocess_text,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LENGTH,\n",
    ")\n",
    "\n",
    "# We will adapt the vectorizer to both the questions and answers\n",
    "# This dataset is batched to parallelize and speed up the process\n",
    "vectorizer.adapt(tf.data.Dataset.from_tensor_slices(real_titles).batch(128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(inputs, outputs):\n",
    "    inputs, outputs = vectorizer(inputs), vectorizer(outputs)\n",
    "    # One extra padding token to the right to match the output shape\n",
    "    outputs = tf.pad(outputs, [[0, 1]])\n",
    "    return (\n",
    "        {\"encoder_inputs\": inputs, \"decoder_inputs\": outputs[:-1]},\n",
    "        {\"outputs\": outputs[1:]},\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "val_dataset = val_dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding (Position  (None, None, 256)   2565120     ['encoder_inputs[0][0]']         \n",
      " alEmbedding)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " f_net_encoder (FNetEncoder)    (None, None, 256)    263936      ['positional_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " outputs (Functional)           (None, None, 10000)  9606672     ['decoder_inputs[0][0]',         \n",
      "                                                                  'f_net_encoder[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,435,728\n",
      "Trainable params: 12,435,728\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "#from tensorflow.python.framework.ops import disable_eager_execution\n",
    "#disable_eager_execution()\n",
    "\n",
    "class FNetEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, **kwargs):\n",
    "        super(FNetEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Casting the inputs to complex64\n",
    "        inp_complex = tf.cast(inputs, tf.complex64)\n",
    "        # Projecting the inputs to the frequency domain using FFT2D and\n",
    "        # extracting the real part of the output\n",
    "        fft = tf.math.real(tf.signal.fft2d(inp_complex))\n",
    "        proj_input = self.layernorm_1(inputs + fft)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class FNetDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(FNetDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    encoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
    "    x = PositionalEmbedding(MAX_LENGTH, VOCAB_SIZE, EMBED_DIM)(encoder_inputs)\n",
    "    encoder_outputs = FNetEncoder(EMBED_DIM, LATENT_DIM)(x)\n",
    "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "    decoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
    "    encoded_seq_inputs = keras.Input(\n",
    "        shape=(None, EMBED_DIM), name=\"decoder_state_inputs\"\n",
    "    )\n",
    "    x = PositionalEmbedding(MAX_LENGTH, VOCAB_SIZE, EMBED_DIM)(decoder_inputs)\n",
    "    x = FNetDecoder(EMBED_DIM, LATENT_DIM, NUM_HEADS)(x, encoded_seq_inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    decoder_outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "    decoder = keras.Model(\n",
    "        [decoder_inputs, encoded_seq_inputs], decoder_outputs, name=\"outputs\"\n",
    "    )\n",
    "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "    fnet = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"fnet\")\n",
    "    return fnet\n",
    "\n",
    "fnet = create_model()\n",
    "fnet.compile(\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "fnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/188 [..............................] - ETA: 9s - loss: 5.5123 - accuracy: 0.0712      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 16:41:18.866591: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 10s 39ms/step - loss: 3.8582 - accuracy: 0.2028 - val_loss: 3.4746 - val_accuracy: 0.2679\n"
     ]
    }
   ],
   "source": [
    "history = fnet.fit(train_dataset, epochs=1, validation_data=val_dataset)\n",
    "\n",
    "#history = model.fit(x_partial_train, y_partial_train, epochs = 20, batch_size = BATCH_SIZE, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 2, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
